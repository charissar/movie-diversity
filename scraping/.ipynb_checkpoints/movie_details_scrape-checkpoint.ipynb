{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Dropping Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports = []\n",
    "for i in range(1,41):\n",
    "    imports.append('genre_exports/export_%s.json' %(str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imp in imports:\n",
    "    movies_df = movies_df.append(pd.read_json(imp, orient='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies_df.drop_duplicates(subset='ID',keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop NaN Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29609"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['Rating'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.dropna(subset = ['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77297"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Movies with Drop Movies with 1000 Votes or More"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['Votes'] = movies['Votes'].str.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# movies['Votes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['Votes'] = movies['Votes'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29717"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies[movies['Votes'] >= 500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies[movies['Votes'] >= 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Details with Movie URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29717"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['http://www.imdb.com/title/tt0006206/',\n",
       "       'http://www.imdb.com/title/tt0009682/',\n",
       "       'http://www.imdb.com/title/tt0015163/',\n",
       "       'http://www.imdb.com/title/tt0015324/',\n",
       "       'http://www.imdb.com/title/tt0017925/',\n",
       "       'http://www.imdb.com/title/tt0018578/',\n",
       "       'http://www.imdb.com/title/tt0019421/',\n",
       "       'http://www.imdb.com/title/tt0020815/',\n",
       "       'http://www.imdb.com/title/tt0021079/',\n",
       "       'http://www.imdb.com/title/tt0022753/',\n",
       "       ...\n",
       "       'http://www.imdb.com/title/tt0439504/',\n",
       "       'http://www.imdb.com/title/tt0457530/',\n",
       "       'http://www.imdb.com/title/tt0495747/',\n",
       "       'http://www.imdb.com/title/tt1384925/',\n",
       "       'http://www.imdb.com/title/tt1388402/',\n",
       "       'http://www.imdb.com/title/tt1555110/',\n",
       "       'http://www.imdb.com/title/tt2014202/',\n",
       "       'http://www.imdb.com/title/tt2140381/',\n",
       "       'http://www.imdb.com/title/tt4893452/',\n",
       "       'http://www.imdb.com/title/tt5143890/'],\n",
       "      dtype='object', length=29717)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_urls = list(movies.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29717"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_urls = sorted(movie_urls,reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get Movie Details\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "movies_scraped = 0\n",
    "movie_details = {}\n",
    "movie_index = 0                       \n",
    "prefix = 'http://www.imdb.com'\n",
    "export_number = 1\n",
    "export_no = str(export_number)\n",
    "load_attempts = 0\n",
    "\n",
    "def movie_scraper():\n",
    "    global movie_index\n",
    "    \n",
    "    print(str(datetime.now()),': working on export ' + export_no)\n",
    "    \n",
    "    for url in movie_urls[movie_index:3000]:\n",
    "        if (movie_index+1) % 20 == 0:\n",
    "            time.sleep(1.5)\n",
    "            print('%d: %s' %(movie_index+1, url))\n",
    "        page = request_page(url)\n",
    "        get_movie_details(url, page)\n",
    "        movie_index += 1\n",
    "    \n",
    "    export_to_json(movie_details)\n",
    "    print(\"Done\")\n",
    "    \n",
    "def request_page(url):\n",
    "    global load_attempts\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return(response.text)\n",
    "        load_attempts = 0\n",
    "    else:\n",
    "        print(response.status_code,'for %s' %(url))\n",
    "        if response.status_code != 404:\n",
    "            if load_attempts == 10:\n",
    "                time.sleep(60)\n",
    "            else:\n",
    "                time.sleep(10)\n",
    "            request_page(url)\n",
    "            load_attempts += 1\n",
    "\n",
    "def get_movie_details(url, page):\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    movie_details[url] = {}\n",
    "    \n",
    "    plot_wrapper = soup.find('div', class_='plot_summary_wrapper')\n",
    "\n",
    "    if plot_wrapper:\n",
    "        if plot_wrapper.find(text=re.compile('Director:')):\n",
    "            directorURL = plot_wrapper.find(text=re.compile('Director:'))\n",
    "        elif plot_wrapper.find(text=re.compile('Directors:')):\n",
    "            directorURL = plot_wrapper.find(text=re.compile('Directors:'))\n",
    "        else:\n",
    "            directorURL = None\n",
    "    directorURL = directorURL.parent.parent if directorURL else None\n",
    "    directorURL = directorURL.find('a') if directorURL else None\n",
    "    director = directorURL.text if directorURL else None\n",
    "    directorURL = directorURL['href'] if directorURL else None\n",
    "    directorURL = prefix+directorURL.split(\"?\")[0] if directorURL else None\n",
    "    movie_details[url]['Director'] = director\n",
    "    movie_details[url]['Director_URL'] = directorURL\n",
    "\n",
    "    if plot_wrapper:\n",
    "        if plot_wrapper.find(text=re.compile('Stars:')):\n",
    "            starURLs = plot_wrapper.find(text=re.compile('Stars:'))\n",
    "        elif plot_wrapper.find(text=re.compile('Star:')):\n",
    "            starURLs = plot_wrapper.find(text=re.compile('Star:'))\n",
    "        else:\n",
    "            starURLs = None\n",
    "    starURLs = starURLs.parent.parent if starURLs else None\n",
    "    starURLs = starURLs.findAll('a') if starURLs else None\n",
    "    if starURLs:\n",
    "        if len(starURLs) == 4:\n",
    "            starURLs = [[star['href'],star.text] for star in starURLs[:-1]]\n",
    "        else:\n",
    "            starURLs = [[star['href'],star.text] for star in starURLs]\n",
    "    if starURLs:\n",
    "        i = 0\n",
    "        while len(starURLs) >= i+1:\n",
    "            for URL in starURLs:\n",
    "                star = starURLs[i]\n",
    "                movie_details[url]['Star%s' %str(i+1)] = star[1].split('\\n')[0].strip() if star[1] else None\n",
    "                movie_details[url]['Star%s_URL' %str(i+1)] = prefix+star[0].split(\"?\")[0] if star[0] else None\n",
    "            i += 1 \n",
    "    \n",
    "    title = soup.find('div', class_='title_wrapper').find('h1',itemprop='name')\n",
    "    title = title.contents[0].replace(u'\\xa0', u'')\n",
    "    movie_details[url]['Title'] = title\n",
    "\n",
    "    release_date = soup.find('div', class_='title_wrapper')\n",
    "    release_date = release_date.findAll('a') if release_date else None\n",
    "    release_date = release_date[-1] if release_date else None\n",
    "    release_date = release_date.find('meta') if release_date else None\n",
    "    release_date = str(release_date) if release_date else None\n",
    "    release_date = re.sub('[^0-9-]+','', release_date) if release_date else None\n",
    "    movie_details[url]['Release Date'] = release_date\n",
    "\n",
    "    title_details = soup.find(id='titleDetails')\n",
    "    \n",
    "    production_company = title_details.find(text=re.compile('Production Co:')) if title_details else None\n",
    "    production_company = production_company.parent.parent if production_company else None\n",
    "    production_company = production_company.find('a') if production_company else None\n",
    "    production_company = production_company.text if production_company else None\n",
    "    movie_details[url]['Production Company'] = production_company\n",
    "\n",
    "    country = title_details.find(text=re.compile('Country:')) if title_details else None\n",
    "    country = country.parent.parent if country else None\n",
    "    country = country.find('a') if country else None\n",
    "    country = country.text if country else None\n",
    "    movie_details[url]['Country'] = country\n",
    "\n",
    "    language = title_details.find(text=re.compile('Language:')) if title_details else None\n",
    "    language = language.parent.parent if language else None\n",
    "    language = language.find('a') if language else None\n",
    "    language = language.text if language else None\n",
    "    movie_details[url]['Language'] = language\n",
    "\n",
    "    primary_filming_location = title_details.find(text=re.compile('Filming Locations:')) if title_details else None\n",
    "    primary_filming_location = primary_filming_location.parent.parent if primary_filming_location else None\n",
    "    primary_filming_location = primary_filming_location.find('a') if primary_filming_location else None\n",
    "    primary_filming_location= primary_filming_location.text if primary_filming_location else None\n",
    "    movie_details[url]['Primary Filming Location'] = primary_filming_location\n",
    "\n",
    "    budget = title_details.find(text=re.compile('Budget:')) if title_details else None\n",
    "    budget = budget.parent.parent if budget else None\n",
    "    budget = budget.text.strip() if budget else None\n",
    "    budget = re.sub('[^0-9]+','', budget) if budget else None\n",
    "    movie_details[url]['Budget'] = budget\n",
    "\n",
    "    opening_weekend_usa = title_details.find(text=re.compile('Opening Weekend USA:')) if title_details else None\n",
    "    opening_weekend_usa = opening_weekend_usa.parent.parent if opening_weekend_usa else None\n",
    "    opening_weekend_usa = opening_weekend_usa.text.strip() if opening_weekend_usa else None\n",
    "    opening_weekend_usa = re.sub('[^0-9]+','', opening_weekend_usa) if opening_weekend_usa else None\n",
    "    movie_details[url]['Opening Weekend USA'] = opening_weekend_usa\n",
    "\n",
    "    #rename gross to gross USA in listing scrape\n",
    "    global_gross = title_details.find(text=re.compile('Cumulative Worldwide Gross:')) if title_details else None\n",
    "    global_gross = global_gross.parent.parent if global_gross else None\n",
    "    global_gross = global_gross.text.strip() if global_gross else None\n",
    "    global_gross = re.sub('[^0-9]+','', global_gross) if global_gross else None\n",
    "    movie_details[url]['Cumulative Worldwide Gross'] = global_gross\n",
    "\n",
    "    gross_usa = title_details.find(text=re.compile('Gross USA:')) if title_details else None\n",
    "    gross_usa = gross_usa.parent.parent if gross_usa else None\n",
    "    gross_usa = gross_usa.text.strip() if gross_usa else None\n",
    "    gross_usa = re.sub('[^0-9]+','', gross_usa) if gross_usa else None\n",
    "    movie_details[url]['Gross USA'] = gross_usa\n",
    "\n",
    "    go_to_next_and_export()\n",
    "\n",
    "def go_to_next_and_export():\n",
    "    global movies_scraped\n",
    "    global movie_details\n",
    "    \n",
    "    movies_scraped+=1\n",
    "\n",
    "    if len(movie_details) == 1000:                                         \n",
    "        export_to_json(movie_details)\n",
    "        movies_scraped = 0\n",
    "        movie_details = {}\n",
    "\n",
    "def export_to_json(movie_details):\n",
    "    global export_no\n",
    "    global export_number\n",
    "    with open('movie_details_export_%s.json' %(export_no),'w')  as f:\n",
    "        json.dump(movie_details,f)\n",
    "\n",
    "    export_number += 1\n",
    "    export_no = str(export_number)\n",
    "    print(str(datetime.now()),': working on export ' + export_no)\n",
    "\n",
    "movie_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
